# ç¤ºä¾‹ï¼šå¦‚ä½•æ·»åŠ æ–°çš„åˆ†ææœåŠ¡å™¨
# è¿™ä¸ªæ–‡ä»¶å±•ç¤ºäº†å¦‚ä½•åˆ›å»ºä¸€ä¸ªæ–°çš„å›å½’åˆ†ææœåŠ¡å™¨

from mcp.server.fastmcp import FastMCP
from typing import List, Optional, Dict, Any
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import json
import os
import sys

# æ·»åŠ è‡ªå®šä¹‰ç±»å‹è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from custom_types.types import ReadDataParam

# åˆ›å»ºMCPæœåŠ¡å™¨å®ä¾‹
mcp = FastMCP('RegressionAnalysisServer')

@mcp.tool()
async def linear_regression_analysis(
    read_data_param: ReadDataParam,
    target_variable: str,
    feature_variables: List[str],
    test_size: float = 0.2,
    include_intercept: bool = True,
    **kwargs
) -> str:
    """
    æ‰§è¡Œçº¿æ€§å›å½’åˆ†æ
    
    Args:
        read_data_param: æ•°æ®è¯»å–å‚æ•°
        target_variable: ç›®æ ‡å˜é‡ï¼ˆå› å˜é‡ï¼‰
        feature_variables: ç‰¹å¾å˜é‡åˆ—è¡¨ï¼ˆè‡ªå˜é‡ï¼‰
        test_size: æµ‹è¯•é›†æ¯”ä¾‹ï¼Œé»˜è®¤0.2
        include_intercept: æ˜¯å¦åŒ…å«æˆªè·é¡¹ï¼Œé»˜è®¤True
        
    Returns:
        str: å›å½’åˆ†æç»“æœçš„Markdownæ ¼å¼æŠ¥å‘Š
    """
    try:
        # è¯»å–æ•°æ®
        if read_data_param.file_path:
            if read_data_param.file_path.endswith('.csv'):
                df = pd.read_csv(read_data_param.file_path)
            elif read_data_param.file_path.endswith('.xlsx'):
                df = pd.read_excel(read_data_param.file_path)
            else:
                return "âŒ **é”™è¯¯**: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨CSVæˆ–Excelæ–‡ä»¶"
        else:
            return "âŒ **é”™è¯¯**: æœªæä¾›æ•°æ®æ–‡ä»¶è·¯å¾„"
        
        # éªŒè¯å˜é‡æ˜¯å¦å­˜åœ¨
        missing_vars = []
        if target_variable not in df.columns:
            missing_vars.append(target_variable)
        for var in feature_variables:
            if var not in df.columns:
                missing_vars.append(var)
        
        if missing_vars:
            return f"âŒ **é”™è¯¯**: ä»¥ä¸‹å˜é‡åœ¨æ•°æ®ä¸­ä¸å­˜åœ¨: {', '.join(missing_vars)}"
        
        # å‡†å¤‡æ•°æ®
        X = df[feature_variables]
        y = df[target_variable]
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        if X.isnull().any().any() or y.isnull().any():
            # åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œ
            data_clean = df[feature_variables + [target_variable]].dropna()
            X = data_clean[feature_variables]
            y = data_clean[target_variable]
            missing_count = len(df) - len(data_clean)
            if missing_count > 0:
                missing_info = f"\nâš ï¸ **æ³¨æ„**: å·²åˆ é™¤ {missing_count} è¡ŒåŒ…å«ç¼ºå¤±å€¼çš„æ•°æ®"
            else:
                missing_info = ""
        else:
            missing_info = ""
        
        # æ£€æŸ¥æ•°æ®é‡
        if len(X) < 10:
            return "âŒ **é”™è¯¯**: æœ‰æ•ˆæ•°æ®é‡ä¸è¶³ï¼ˆå°‘äº10è¡Œï¼‰ï¼Œæ— æ³•è¿›è¡Œå¯é çš„å›å½’åˆ†æ"
        
        # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42
        )
        
        # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        model = LinearRegression(fit_intercept=include_intercept)
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        train_r2 = r2_score(y_train, y_train_pred)
        test_r2 = r2_score(y_test, y_test_pred)
        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""# ğŸ“Š çº¿æ€§å›å½’åˆ†ææŠ¥å‘Š

## ğŸ“‹ åˆ†ææ¦‚å†µ
- **ç›®æ ‡å˜é‡**: {target_variable}
- **ç‰¹å¾å˜é‡**: {', '.join(feature_variables)}
- **æ ·æœ¬æ€»æ•°**: {len(df):,} è¡Œ
- **æœ‰æ•ˆæ ·æœ¬**: {len(X):,} è¡Œ{missing_info}
- **è®­ç»ƒé›†**: {len(X_train):,} è¡Œ ({(1-test_size)*100:.0f}%)
- **æµ‹è¯•é›†**: {len(X_test):,} è¡Œ ({test_size*100:.0f}%)

## ğŸ“ˆ æ¨¡å‹æ€§èƒ½

### å†³å®šç³»æ•° (RÂ²)
- **è®­ç»ƒé›† RÂ²**: {train_r2:.4f}
- **æµ‹è¯•é›† RÂ²**: {test_r2:.4f}

### å‡æ–¹æ ¹è¯¯å·® (RMSE)
- **è®­ç»ƒé›† RMSE**: {train_rmse:.4f}
- **æµ‹è¯•é›† RMSE**: {test_rmse:.4f}

## ğŸ” å›å½’ç³»æ•°

| å˜é‡ | ç³»æ•° | æ ‡å‡†åŒ–ç³»æ•° |
|------|------|------------|"""

        # è®¡ç®—æ ‡å‡†åŒ–ç³»æ•°
        X_std = (X_train - X_train.mean()) / X_train.std()
        y_std = (y_train - y_train.mean()) / y_train.std()
        model_std = LinearRegression(fit_intercept=False)
        model_std.fit(X_std, y_std)
        
        for i, var in enumerate(feature_variables):
            coef = model.coef_[i]
            std_coef = model_std.coef_[i]
            report += f"\n| {var} | {coef:.4f} | {std_coef:.4f} |"
        
        if include_intercept:
            report += f"\n| æˆªè·é¡¹ | {model.intercept_:.4f} | - |"
        
        # æ¨¡å‹è§£é‡Š
        report += f"""

## ğŸ“ ç»“æœè§£é‡Š

### æ¨¡å‹æ‹Ÿåˆåº¦
- RÂ² = {test_r2:.4f} è¡¨ç¤ºæ¨¡å‹èƒ½å¤Ÿè§£é‡Šç›®æ ‡å˜é‡ {test_r2*100:.1f}% çš„å˜å¼‚
"""
        
        if test_r2 >= 0.7:
            fit_quality = "**ä¼˜ç§€** ğŸŒŸ"
        elif test_r2 >= 0.5:
            fit_quality = "**è‰¯å¥½** âœ…"
        elif test_r2 >= 0.3:
            fit_quality = "**ä¸€èˆ¬** âš ï¸"
        else:
            fit_quality = "**è¾ƒå·®** âŒ"
        
        report += f"- æ‹Ÿåˆè´¨é‡: {fit_quality}\n"
        
        # è¿‡æ‹Ÿåˆæ£€æŸ¥
        overfitting = train_r2 - test_r2
        if overfitting > 0.1:
            report += f"- âš ï¸ **æ³¨æ„**: å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆï¼ˆè®­ç»ƒé›†RÂ²æ¯”æµ‹è¯•é›†RÂ²é«˜ {overfitting:.3f}ï¼‰\n"
        
        # å˜é‡é‡è¦æ€§
        report += "\n### å˜é‡é‡è¦æ€§\n"
        importance = [(var, abs(coef)) for var, coef in zip(feature_variables, model_std.coef_)]
        importance.sort(key=lambda x: x[1], reverse=True)
        
        for i, (var, imp) in enumerate(importance, 1):
            report += f"{i}. **{var}**: æ ‡å‡†åŒ–ç³»æ•°ç»å¯¹å€¼ = {imp:.4f}\n"
        
        # å»ºè®®
        report += f"""

## ğŸ’¡ å»ºè®®

### æ¨¡å‹ä½¿ç”¨å»ºè®®
"""
        if test_r2 >= 0.5:
            report += "- âœ… æ¨¡å‹æ‹Ÿåˆåº¦è¾ƒå¥½ï¼Œå¯ä»¥ç”¨äºé¢„æµ‹å’Œè§£é‡Š\n"
        else:
            report += "- âš ï¸ æ¨¡å‹æ‹Ÿåˆåº¦æœ‰é™ï¼Œå»ºè®®è€ƒè™‘æ·»åŠ æ›´å¤šç‰¹å¾æˆ–ä½¿ç”¨éçº¿æ€§æ¨¡å‹\n"
        
        if overfitting > 0.1:
            report += "- ğŸ”„ å»ºè®®ä½¿ç”¨äº¤å‰éªŒè¯æˆ–æ­£åˆ™åŒ–æ–¹æ³•å‡å°‘è¿‡æ‹Ÿåˆ\n"
        
        report += f"""
### è¿›ä¸€æ­¥åˆ†æå»ºè®®
- ğŸ” æ£€æŸ¥æ®‹å·®åˆ†å¸ƒï¼ŒéªŒè¯çº¿æ€§å‡è®¾
- ğŸ“Š è¿›è¡Œå¤šé‡å…±çº¿æ€§è¯Šæ–­
- ğŸ¯ è€ƒè™‘ç‰¹å¾å·¥ç¨‹å’Œå˜é‡å˜æ¢
- ğŸ“ˆ å°è¯•å…¶ä»–å›å½’æ–¹æ³•ï¼ˆå¦‚å²­å›å½’ã€Lassoå›å½’ï¼‰

---
*åˆ†æå®Œæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        return report
        
    except Exception as e:
        return f"âŒ **åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯**: {str(e)}"

@mcp.tool()
async def polynomial_regression_analysis(
    read_data_param: ReadDataParam,
    target_variable: str,
    feature_variable: str,
    degree: int = 2,
    test_size: float = 0.2,
    **kwargs
) -> str:
    """
    æ‰§è¡Œå¤šé¡¹å¼å›å½’åˆ†æï¼ˆå•å˜é‡ï¼‰
    
    Args:
        read_data_param: æ•°æ®è¯»å–å‚æ•°
        target_variable: ç›®æ ‡å˜é‡
        feature_variable: ç‰¹å¾å˜é‡ï¼ˆå•ä¸ªï¼‰
        degree: å¤šé¡¹å¼æ¬¡æ•°ï¼Œé»˜è®¤2
        test_size: æµ‹è¯•é›†æ¯”ä¾‹ï¼Œé»˜è®¤0.2
        
    Returns:
        str: å¤šé¡¹å¼å›å½’åˆ†æç»“æœ
    """
    try:
        # è¯»å–æ•°æ®
        if read_data_param.file_path:
            if read_data_param.file_path.endswith('.csv'):
                df = pd.read_csv(read_data_param.file_path)
            elif read_data_param.file_path.endswith('.xlsx'):
                df = pd.read_excel(read_data_param.file_path)
            else:
                return "âŒ **é”™è¯¯**: ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"
        else:
            return "âŒ **é”™è¯¯**: æœªæä¾›æ•°æ®æ–‡ä»¶è·¯å¾„"
        
        # éªŒè¯å˜é‡
        if target_variable not in df.columns:
            return f"âŒ **é”™è¯¯**: ç›®æ ‡å˜é‡ '{target_variable}' ä¸å­˜åœ¨"
        if feature_variable not in df.columns:
            return f"âŒ **é”™è¯¯**: ç‰¹å¾å˜é‡ '{feature_variable}' ä¸å­˜åœ¨"
        
        # å‡†å¤‡æ•°æ®
        data_clean = df[[feature_variable, target_variable]].dropna()
        X = data_clean[[feature_variable]]
        y = data_clean[target_variable]
        
        if len(X) < 10:
            return "âŒ **é”™è¯¯**: æœ‰æ•ˆæ•°æ®é‡ä¸è¶³"
        
        # åˆ›å»ºå¤šé¡¹å¼ç‰¹å¾
        from sklearn.preprocessing import PolynomialFeatures
        poly_features = PolynomialFeatures(degree=degree)
        X_poly = poly_features.fit_transform(X)
        
        # åˆ†å‰²æ•°æ®
        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(
            X_poly, y, test_size=test_size, random_state=42
        )
        
        # è®­ç»ƒæ¨¡å‹
        model = LinearRegression()
        model.fit(X_train, y_train)
        
        # é¢„æµ‹å’Œè¯„ä¼°
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)
        train_r2 = r2_score(y_train, y_train_pred)
        test_r2 = r2_score(y_test, y_test_pred)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""# ğŸ“ˆ å¤šé¡¹å¼å›å½’åˆ†ææŠ¥å‘Š

## ğŸ“‹ åˆ†ææ¦‚å†µ
- **ç›®æ ‡å˜é‡**: {target_variable}
- **ç‰¹å¾å˜é‡**: {feature_variable}
- **å¤šé¡¹å¼æ¬¡æ•°**: {degree}
- **æœ‰æ•ˆæ ·æœ¬**: {len(X):,} è¡Œ

## ğŸ“Š æ¨¡å‹æ€§èƒ½
- **è®­ç»ƒé›† RÂ²**: {train_r2:.4f}
- **æµ‹è¯•é›† RÂ²**: {test_r2:.4f}

## ğŸ” å¤šé¡¹å¼æ–¹ç¨‹
"""
        
        # æ„å»ºæ–¹ç¨‹
        feature_names = poly_features.get_feature_names_out([feature_variable])
        equation = f"{target_variable} = "
        terms = []
        
        for i, (coef, name) in enumerate(zip(model.coef_, feature_names)):
            if abs(coef) > 1e-10:  # å¿½ç•¥å¾ˆå°çš„ç³»æ•°
                if name == '1':
                    terms.append(f"{coef:.4f}")
                else:
                    terms.append(f"{coef:.4f}Ã—{name}")
        
        equation += " + ".join(terms)
        if model.intercept_ != 0:
            equation += f" + {model.intercept_:.4f}"
        
        report += f"```\n{equation}\n```\n"
        
        # æ¨¡å‹è¯„ä¼°
        if test_r2 >= 0.7:
            quality = "**ä¼˜ç§€** ğŸŒŸ"
        elif test_r2 >= 0.5:
            quality = "**è‰¯å¥½** âœ…"
        else:
            quality = "**éœ€è¦æ”¹è¿›** âš ï¸"
        
        report += f"""
## ğŸ“ ç»“æœè§£é‡Š
- **æ‹Ÿåˆè´¨é‡**: {quality}
- **è§£é‡Šèƒ½åŠ›**: æ¨¡å‹èƒ½è§£é‡Š {test_r2*100:.1f}% çš„å˜å¼‚

## ğŸ’¡ å»ºè®®
- å¦‚æœæ‹Ÿåˆåº¦ä¸ç†æƒ³ï¼Œå¯ä»¥å°è¯•è°ƒæ•´å¤šé¡¹å¼æ¬¡æ•°
- æ³¨æ„é¿å…è¿‡æ‹Ÿåˆï¼Œç‰¹åˆ«æ˜¯é«˜æ¬¡å¤šé¡¹å¼
- å¯ä»¥è€ƒè™‘æ·»åŠ æ›´å¤šç‰¹å¾å˜é‡
"""
        
        return report
        
    except Exception as e:
        return f"âŒ **åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯**: {str(e)}"

# å¯åŠ¨æœåŠ¡å™¨çš„ä¸»å‡½æ•°
if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨å›å½’åˆ†ææœåŠ¡å™¨...")
    print("ğŸ“¡ æœåŠ¡å™¨åœ°å€: http://127.0.0.1:8001/sse")
    print("ğŸ”§ æ”¯æŒçš„åˆ†æç±»å‹: regression")
    print("ğŸ“Š å¯ç”¨å·¥å…·:")
    print("  - linear_regression_analysis: çº¿æ€§å›å½’åˆ†æ")
    print("  - polynomial_regression_analysis: å¤šé¡¹å¼å›å½’åˆ†æ")
    
    # åœ¨ç«¯å£8001ä¸Šå¯åŠ¨æœåŠ¡å™¨ï¼ˆé¿å…ä¸ç›¸å…³æ€§åˆ†ææœåŠ¡å™¨å†²çªï¼‰
    mcp.run(transport='sse', port=8001) 