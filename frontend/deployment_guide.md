# æ™ºèƒ½æ•°æ®åˆ†æç³»ç»Ÿéƒ¨ç½²æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å¯åŠ¨ç›¸å…³æ€§åˆ†ææœåŠ¡å™¨ï¼ˆå·²æœ‰ï¼‰
```bash
cd analysis-agent/server
python corr_server.py
```
æœåŠ¡å™¨å°†åœ¨ `http://127.0.0.1:8000/sse` å¯åŠ¨

### 2. å¯åŠ¨é€šç”¨åˆ†æåç«¯
```bash
cd analysis-agent/frontend
python backend.py
```
åç«¯å°†åœ¨ `http://127.0.0.1:8001` å¯åŠ¨

### 3. æµ‹è¯•ç³»ç»ŸçŠ¶æ€
```bash
curl http://localhost:8001/status
```

## ğŸ“‹ ç³»ç»Ÿè¦æ±‚

### Pythonä¾èµ–
```bash
pip install fastapi uvicorn pandas numpy scikit-learn
pip install mcp agents  # æ ¹æ®å®é™…MCPåº“å®‰è£…
```

### ç›®å½•ç»“æ„
```
analysis-agent/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ backend.py                          # é€šç”¨åˆ†æåç«¯
â”‚   â”œâ”€â”€ intelligent_analysis_backend_guide.md
â”‚   â”œâ”€â”€ deployment_guide.md
â”‚   â””â”€â”€ example_new_server.py               # æ–°æœåŠ¡å™¨ç¤ºä¾‹
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ corr_server.py                      # ç›¸å…³æ€§åˆ†ææœåŠ¡å™¨
â”‚   â””â”€â”€ corr_final.py                       # ç›¸å…³æ€§åˆ†ææ ¸å¿ƒé€»è¾‘
â””â”€â”€ custom_types/
    â””â”€â”€ types.py                            # å…±äº«æ•°æ®ç±»å‹
```

## ğŸ”§ æ·»åŠ æ–°åˆ†æåŠŸèƒ½

### æ­¥éª¤1ï¼šåˆ›å»ºæ–°çš„MCPæœåŠ¡å™¨

ä»¥å›å½’åˆ†æä¸ºä¾‹ï¼š

```python
# åˆ›å»º regression_server.py
from mcp.server.fastmcp import FastMCP
from custom_types.types import ReadDataParam

mcp = FastMCP('RegressionServer')

@mcp.tool()
async def linear_regression_analysis(
    read_data_param: ReadDataParam,
    target_variable: str,
    feature_variables: List[str],
    **kwargs
) -> str:
    # å®ç°å›å½’åˆ†æé€»è¾‘
    pass

if __name__ == '__main__':
    mcp.run(transport='sse', port=8002)  # ä½¿ç”¨æ–°ç«¯å£
```

### æ­¥éª¤2ï¼šæ›´æ–°åç«¯é…ç½®

åœ¨ `backend.py` ä¸­æ›´æ–° `MCP_SERVERS_CONFIG`ï¼š

```python
MCP_SERVERS_CONFIG["regression"] = MCPServerConfig(
    name="regression",
    url="http://127.0.0.1:8002/sse",
    analysis_types=[AnalysisType.REGRESSION],
    enabled=True  # è®¾ä¸ºTrueå¯ç”¨
)
```

### æ­¥éª¤3ï¼šå¯åŠ¨æ–°æœåŠ¡å™¨

```bash
python regression_server.py
```

### æ­¥éª¤4ï¼šé‡å¯åç«¯

```bash
# åœæ­¢ç°æœ‰åç«¯ (Ctrl+C)
python backend.py
```

## ğŸŒ APIä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€åˆ†æè¯·æ±‚
```python
import requests

# ç›¸å…³æ€§åˆ†æ
response = requests.post("http://localhost:8001/analyze", json={
    "message": "åˆ†ææ¸©åº¦å’Œæ¹¿åº¦çš„ç›¸å…³æ€§",
    "analysis_type": "correlation"
})

print(response.json()["result"])
```

### å¸¦ä¸Šä¸‹æ–‡çš„åˆ†æ
```python
response = requests.post("http://localhost:8001/analyze", json={
    "message": "è¯·åˆ†æé”€å”®æ•°æ®ä¸­ä»·æ ¼å¯¹é”€é‡çš„å½±å“",
    "analysis_type": "regression",
    "context": {
        "dataset": "sales_data.csv",
        "priority": "high"
    }
})
```

### å¯¹è¯å¼åˆ†æ
```python
# ç¬¬ä¸€è½®
response1 = requests.post("http://localhost:8001/analyze", json={
    "message": "æˆ‘æœ‰ä¸€ä¸ªå®¢æˆ·æ•°æ®é›†ï¼Œæƒ³åšèšç±»åˆ†æ"
})

# ç¬¬äºŒè½®ï¼Œå¸¦å†å²
response2 = requests.post("http://localhost:8001/analyze", json={
    "message": "è¯·ä½¿ç”¨K-meansç®—æ³•ï¼Œåˆ†æˆ5ä¸ªç¾¤ç»„",
    "conversation_history": response1.json()["conversation_history"],
    "analysis_type": "clustering"
})
```

## ğŸ” ç³»ç»Ÿç›‘æ§

### æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
```bash
curl http://localhost:8001/status
```

### æŸ¥çœ‹æ”¯æŒçš„åˆ†æç±»å‹
```bash
curl http://localhost:8001/analysis-types
```

### åŠ¨æ€ç®¡ç†æœåŠ¡å™¨
```bash
# å¯ç”¨æœåŠ¡å™¨
curl -X POST http://localhost:8001/servers/regression/enable

# ç¦ç”¨æœåŠ¡å™¨
curl -X POST http://localhost:8001/servers/regression/disable

# æ·»åŠ æ–°æœåŠ¡å™¨
curl -X POST http://localhost:8001/servers/add \
  -H "Content-Type: application/json" \
  -d '{
    "name": "clustering",
    "url": "http://127.0.0.1:8003/sse",
    "analysis_types": ["clustering"],
    "enabled": true
  }'
```

## ğŸ“Š ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

### ä½¿ç”¨Dockeréƒ¨ç½²

åˆ›å»º `Dockerfile`ï¼š
```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8001

CMD ["python", "backend.py"]
```

åˆ›å»º `docker-compose.yml`ï¼š
```yaml
version: '3.8'
services:
  correlation-server:
    build: 
      context: ./server
    ports:
      - "8000:8000"
    
  regression-server:
    build:
      context: ./regression
    ports:
      - "8002:8002"
    
  analysis-backend:
    build:
      context: ./frontend
    ports:
      - "8001:8001"
    depends_on:
      - correlation-server
      - regression-server
```

### ä½¿ç”¨Nginxåå‘ä»£ç†

```nginx
server {
    listen 80;
    server_name your-domain.com;
    
    location /api/ {
        proxy_pass http://localhost:8001/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

## ğŸ› ï¸ å¼€å‘æœ€ä½³å®è·µ

### 1. æœåŠ¡å™¨å¼€å‘è§„èŒƒ

```python
# æ¯ä¸ªåˆ†ææœåŠ¡å™¨åº”è¯¥ï¼š
# 1. ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®ç±»å‹ (ReadDataParam)
# 2. è¿”å›Markdownæ ¼å¼çš„ç»“æœ
# 3. åŒ…å«è¯¦ç»†çš„é”™è¯¯å¤„ç†
# 4. æä¾›å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²

@mcp.tool()
async def your_analysis_function(
    read_data_param: ReadDataParam,
    # å…¶ä»–å‚æ•°...
    **kwargs
) -> str:
    """
    è¯¦ç»†çš„å‡½æ•°è¯´æ˜
    
    Args:
        read_data_param: æ•°æ®è¯»å–å‚æ•°
        # å…¶ä»–å‚æ•°è¯´æ˜...
        
    Returns:
        str: Markdownæ ¼å¼çš„åˆ†æç»“æœ
    """
    try:
        # å®ç°åˆ†æé€»è¾‘
        pass
    except Exception as e:
        return f"âŒ **åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯**: {str(e)}"
```

### 2. é”™è¯¯å¤„ç†ç­–ç•¥

```python
# åœ¨åç«¯ä¸­å®ç°ä¼˜é›…é™çº§
try:
    # å°è¯•ä½¿ç”¨æŒ‡å®šçš„åˆ†æç±»å‹
    result = await analyze_with_specific_type(request)
except Exception:
    # é™çº§åˆ°é€šç”¨åˆ†æ
    result = await analyze_with_general_agent(request)
```

### 3. æ€§èƒ½ä¼˜åŒ–

```python
# ä½¿ç”¨è¿æ¥æ± 
import aiohttp

class MCPServerManager:
    def __init__(self):
        self.session = aiohttp.ClientSession()
    
    async def close(self):
        await self.session.close()
```

### 4. æ—¥å¿—å’Œç›‘æ§

```python
# æ·»åŠ è¯¦ç»†çš„æ—¥å¿—è®°å½•
import logging

logger = logging.getLogger(__name__)

@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    
    logger.info(f"{request.method} {request.url} - {response.status_code} - {process_time:.2f}s")
    return response
```

## ğŸ”’ å®‰å…¨è€ƒè™‘

### 1. æ–‡ä»¶è®¿é—®å®‰å…¨
```python
import os
from pathlib import Path

def validate_file_path(file_path: str) -> bool:
    """éªŒè¯æ–‡ä»¶è·¯å¾„å®‰å…¨æ€§"""
    try:
        # è§£æè·¯å¾„
        path = Path(file_path).resolve()
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„ç›®å½•å†…
        allowed_dirs = ["/data", "/uploads"]
        return any(str(path).startswith(allowed_dir) for allowed_dir in allowed_dirs)
    except:
        return False
```

### 2. è¾“å…¥éªŒè¯
```python
from pydantic import validator

class AnalysisRequest(BaseModel):
    message: str
    
    @validator('message')
    def validate_message(cls, v):
        if len(v) > 10000:  # é™åˆ¶æ¶ˆæ¯é•¿åº¦
            raise ValueError('æ¶ˆæ¯è¿‡é•¿')
        return v
```

### 3. é€Ÿç‡é™åˆ¶
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter

@app.post("/analyze")
@limiter.limit("10/minute")  # æ¯åˆ†é’Ÿæœ€å¤š10æ¬¡è¯·æ±‚
async def analyze_data(request: Request, analysis_request: AnalysisRequest):
    # åˆ†æé€»è¾‘
    pass
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

1. **MCPæœåŠ¡å™¨è¿æ¥å¤±è´¥**
   ```bash
   # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦å¯åŠ¨
   netstat -tlnp | grep :8000
   
   # æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
   sudo ufw status
   
   # æŸ¥çœ‹æœåŠ¡å™¨æ—¥å¿—
   tail -f logs/correlation-server.log
   ```

2. **åˆ†æç»“æœå¼‚å¸¸**
   ```python
   # åœ¨åˆ†æå‡½æ•°ä¸­æ·»åŠ è°ƒè¯•ä¿¡æ¯
   logger.debug(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {df.shape}")
   logger.debug(f"æ•°æ®åˆ—å: {df.columns.tolist()}")
   ```

3. **æ€§èƒ½é—®é¢˜**
   ```bash
   # ç›‘æ§ç³»ç»Ÿèµ„æº
   htop
   
   # æ£€æŸ¥å†…å­˜ä½¿ç”¨
   free -h
   
   # åˆ†ææ…¢æŸ¥è¯¢
   tail -f logs/performance.log | grep "slow"
   ```

### è°ƒè¯•æ¨¡å¼å¯åŠ¨

```bash
# å¯åŠ¨æ—¶å¯ç”¨è°ƒè¯•æ¨¡å¼
export DEBUG=true
python backend.py

# æˆ–è€…åœ¨ä»£ç ä¸­è®¾ç½®
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8001,
        debug=True,  # å¯ç”¨è°ƒè¯•æ¨¡å¼
        reload=True  # å¯ç”¨è‡ªåŠ¨é‡è½½
    )
```

## ğŸ“ˆ æ‰©å±•è®¡åˆ’

### å³å°†æ”¯æŒçš„åˆ†æç±»å‹

1. **èšç±»åˆ†æ** (clustering)
   - K-meansèšç±»
   - å±‚æ¬¡èšç±»
   - DBSCANèšç±»

2. **åˆ†ç±»åˆ†æ** (classification)
   - é€»è¾‘å›å½’
   - å†³ç­–æ ‘
   - éšæœºæ£®æ—

3. **æ—¶é—´åºåˆ—åˆ†æ** (time_series)
   - ARIMAæ¨¡å‹
   - å­£èŠ‚æ€§åˆ†è§£
   - è¶‹åŠ¿åˆ†æ

4. **æè¿°æ€§ç»Ÿè®¡** (descriptive)
   - åŸºç¡€ç»Ÿè®¡é‡
   - åˆ†å¸ƒåˆ†æ
   - å¼‚å¸¸å€¼æ£€æµ‹

### åŠŸèƒ½å¢å¼ºè®¡åˆ’

- ğŸ”„ **è‡ªåŠ¨åŒ–å·¥ä½œæµ**: æ”¯æŒå¤šæ­¥éª¤åˆ†ææµç¨‹
- ğŸ“Š **å¯è§†åŒ–é›†æˆ**: è‡ªåŠ¨ç”Ÿæˆå›¾è¡¨å’Œå¯è§†åŒ–
- ğŸ¤– **æ™ºèƒ½æ¨è**: åŸºäºæ•°æ®ç‰¹å¾æ¨èæœ€ä½³åˆ†ææ–¹æ³•
- ğŸ”— **æ•°æ®æºé›†æˆ**: æ”¯æŒæ•°æ®åº“ã€APIç­‰å¤šç§æ•°æ®æº
- ğŸ“± **ç§»åŠ¨ç«¯æ”¯æŒ**: æä¾›ç§»åŠ¨ç«¯å‹å¥½çš„API

é€šè¿‡è¿™ä¸ªé€šç”¨çš„æ™ºèƒ½æ•°æ®åˆ†æåç«¯ç³»ç»Ÿï¼Œæ‚¨å¯ä»¥è½»æ¾æ„å»ºä¸€ä¸ªåŠŸèƒ½å¼ºå¤§ã€å¯æ‰©å±•çš„æ•°æ®åˆ†æå¹³å°ï¼ 